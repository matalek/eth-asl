% % % % % % % % % % % % % % %
\documentclass[11pt]{article}
\usepackage[a4paper, portrait, margin=1in]{geometry}
% % % % % % % % % % % % % % %


\usepackage{fancyhdr}
\usepackage{siunitx}
\usepackage{amsmath}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\usepackage{array}
\usepackage{booktabs}

\fancypagestyle{firstpagefooter}
{
\lfoot{Version: 25.11.2016}
\cfoot{}
\rfoot{\thepage}
}
\cfoot{\thepage}


\begin{document}

\title{Advanced Systems Lab (Fall'16) -- Third Milestone}

\author{Name: \emph{Aleksander Matusiak}\\Legi number: \emph{16-931-925}}

\date{
\vspace{4cm}
\textbf{Grading} \\
\begin{tabular}{|c|c|}
\hline  \textbf{Section} & \textbf{Points} \\ 
\hline  1 &  \\ 
\hline  2 &  \\ 
\hline  3 &  \\ 
\hline  4 &  \\ 
\hline  5 &  \\ 
\hline \hline Total & \\
\hline 
\end{tabular} 
}

\maketitle
\thispagestyle{firstpagefooter}
\newpage

\section*{Notes on writing the report}

The report does not need to be extensive but it must be concise, complete, and correct. Conciseness is important  in  terms  of  content  and explanations,  focusing  on  what  has  been  done and  explanations  of the results. A long report is not necessarily a better report, especially if there are aspects that  remain  unexplained.  Completeness  implies  that  the  report  should  give  a comprehensive idea of what has been done by mentioning all key aspects of the modeling and analysis effort. Limited analysis because of flaws in the system or lack of experimental data from Milestones 1 or 2 are not  valid  arguments  for  an incomplete  report.  If  bugs  or  lack  of  data  prevent  you  from  doing  a  correct analysis, the system must be debugged and new data collected. In case the system has been modified, include a short description of the changes as an appendix.

Remember  that  this is  a  report  about modeling  and  analyzing the  system you  have  designed  and  built, using  the experimental data you have collected. There is no unique way to do the report and you may choose  to  focus  on  different  aspects  of  the  system  as  long  as  you deliver a  complete analysis of  its behavior. Keep in mind that, \emph{for all queuing models in the report}, you need to explain how the the parameters of the model were determined and from which experiments the data comes from (adding a reference to the exact graph, table, etc. from the previous milestones). You have to find all system metrics that can be derived using the corresponding formulas and then match to the experimental results, explaining the similarities and differences in quantitative and qualitative terms. The calculations and the numbers you derive might need to be explained with references to the logs and sources in the previous reports. Make sure to mark these references, as well as the ones pointing to experimental results clearly. \textit{Missing parts of the above requirements might lead to significant loss of points in each section.}

The report should be organized in sections as explained in the next pages, and each section should address at least the questions mentioned for each point. You might be called for a meeting in person to clarify aspects of the report or the system and to make a short presentation of the work done. By submitting the report, you  confirm  that  you  have  done  the  work  on  your  own,  the  data used comes  from  experiments  your have  done,  you  have  written  the  report  on  your  own,  and  you have  not  copied  neither text nor data from other sources.

\medskip
The milestone is worth 200 points. 


\pagebreak


\section{System as One Unit}\label{sec:system-one-unit}

\iffalse
Length: 1-2 pages

Build an M/M/1 model of your entire system based on the stability trace that you had to run for the first milestone. Explain the characteristics and behavior of the model built, and compare it with the experimental data (collected both outside and inside the middleware). Analyze the modeled and real-life behavior of the system (explain the similarities, the differences, and map them to aspects of the design or the experiments). Make sure to follow the model-related guidelines described in the Notes!
\fi

Throughput measured by the memaslap clients was equal to 13758 operations/second. Therefore, I take arrival rate $\lambda = 13758 \textrm{ ops/s}$.

For this model we take server discipline First Come First Served, with no buffer limitations. The population size is 192 clients and the system is a closed one.

In M/M/1 model we have one queue and one server. As server we will consider memcached server. Since there are actually 3 memcached servers processing requests, we have to calculate the service rate accordingly.

One approach to do it is to take maximum throughput measured during the experiment. This approach has been suggested during the tutorial and gives us a lower bound on a service rate. This is because if system was able at some point in time to have this performance, it means that it is able to perform at least that well. Since the running time of the experiment was pretty long (30 minutes), we can assume that this approximation is good enough.

Another approach to do this would be to calculate the number of requests being actively processed in the middleware, which corresponds to the average parallelism in the middleware. We would then assume that the service time is average time spent in the servers divided by the number of active threads. We still would need to take into the account that this time includes requests being sent over the network, but we could also treat network as a queue. Since servers have only 1 thread working the requests will partially wait in the queue of the server and partially this waiting period will be included in the time spent in the network. However, this approach proved to be inaccurate. For this task I got the following results: on average 38.15 getter threads are busy processing requests and there are on average 1.05 requests in all setter threads (there are 3 of them). So, on average, there are $m = 39.21$ on the fly (sum based on more precise numbers). That would mean service rate approximately 13893 requests/second and would result in a very high utilization - around 99\%. For the second task, however, utilization calculated using this approach resulted in utilization over 1. This is because in order to use this method we have to assume that memcached servers are busy almost all the time and time spent in the network, even without network, would be spent in the queue. However, this is not the case and therefore results of this method are unsatisfactory. 

%I had to improve the logging in my middleware (see apendix) in order to log also current numbers of busy getter threads and number of requests processed currently by setter requests (i.e. number of set requests that have been taken out of the queue but the response for them has not yet been sent to the client). This made it necessary to repeat the experiment.

%Looking at the middleware logs I have calculated, that an average time spent in the servers equals: $T_s = \SI{2841.63}{\micro\second}$, which is the difference between $T\_SendToClient$ and $T\_Dequeue$ (see report for milestone 1.). When it comes to number of requests on the fly I got the following results: on average 38.15 getter threads are busy processing requests and there are on average 1.05 requests in all setter threads (there are 3 of them). So, on average, there are $m = 39.21$ on the fly (sum based on more precise numbers). Based on the previous analysis we can now calculate the service rate appropriate for M/M/1 model:

Looking at the memaslap logs I have calculated that maximum throughput was equal to 16701 requests/second. Therefore, using the first described approach, we have:
$$\mu = 16701\textrm{ requests/second}$$
%$$\mu \approx \frac{39.21}{2841.63} \cdot 10^6 \textrm{ requests/second} \approx 13892.53 \textrm{ requests/second}$$
%In order to calculate mean service rate which includes that many requests are processed in parallel, I had to find out the average number of requests being in the service. In order to do that I had to make some changes in my code (described in the appendix) i I 
This enables us to calculate the offered load:
$$\rho = \frac{\lambda}{\mu} = \frac{13758}{16701} \approx 82.38\%$$
The offered load is below 1, which means that the system is stable.

The utilization can be considered to be pretty high. It stems from the fact that for stability experiment I have used only 16 threads. As the experiments from second milestones have shown, for 16 threads we get worse performance than for the higher number of threads. This means that threads are mostly busy and since the high utilization of the system. What is more, the component that causes this high utilization is accepting thread. As I have pointed out in the report for milestone 2, this component at some point becomes the bottleneck of the system. For stability trace It was still not the case (too low number of threads), but this component either way is not that effective and affects the offered load.

% Maybe remove
It is also worth pointing out, that the average number of set requests being serviced is quite low, considering that there are 3 setter threads (one for each queue) which process requests asynchronously (one thread can process more than one requests at the same time). This is because set requests are only 1\% of all requests, so they are not many of them and although it takes longer to process them, the low number of them leads to low number of them being processed at the same time.

The  probability that there are zero jobs in the system equals: $$1 - \rho \approx 17.62\%$$ 
This result is not consistent with the data collected from the middleware. We can calculate that the first percentile of number of active getter threads is already equal 8. This means that 99\% of the time they are not less than 8 get requests being processed in the system. This contradicts result from the theory. This can be explained in a following way: M/M/1 models do not take into the account the possibility that several requests can be processed at the same time. Based on the high service rate from model we can get that the single request is processed really quickly, so that they don't queue that much. However, in reality, requests are processed for a longer time, but they are several requests processed in parallel. In a similar way, when we calculate the average number of requests in the system, we get contradicting results. We have:
$$E[n] = \frac{\rho}{1 - \rho} \approx{82.38\%}/{17.62\%} \approx 4.67$$
We know from the collected logs that on average there are around 39 requests being processed at the same time. This means that they are at least 39 requests in the whole system. The reason for this discrepancy is the same as mentioned above - M/M/1 model does not consider the parallelism. 

When we take a look at calculated mean number of jobs in the queue and in the service we still see discrepancies, but there is one thing that is similar to measured values:
$$E[n_q] = \frac{\rho^2}{1-\rho} \approx 3.85$$
$$E[n_s] = \rho \approx 0.82$$
The ratio of jobs in the queue to jobs in the system is equal to $\rho \approx 0.823$ (simple formulas transformation). Under the assumption that almost all of 192 requests are in the system, we have that around 39 requests are being processed (see earlier) and therefore $192-39 = 153$ jobs are in the queue. The ratio between jobs in the queue and jobs in the system equals here to $\frac{153}{192} \approx 0.797$. These values are relatively close to each other, so we can say that this ration has been well predicted by our model.

%The probability that there are $n$ jobs in the system equals approximately $p_n = 0.97\% \cdot 99.03\%^n$. We can also calculate how many requests are in system in total:
%$$E[n] = \frac{\rho}{1 - \rho} \approx{99.03\%}/{0.98\%} \approx 102.52$$
%Let me remind here that there are 192 clients. Calculated number is therefore plausible. Requests spend also significant amount of time traveling in the network between memaslap clients and middleware, which causes the calculated number of requests in the system to be a lot less than the number of clients.

We can calculate also mean response time:
$$E[r] = (1/\mu)/(1 - \rho) \approx \frac{1}{16701 \textrm{ requests/second} \cdot 17.62\%} \approx \SI{339.82}{\micro\second}$$
When we look at the data collected from the middleware we can see that the mean time spent in the middleware equals approximately \SI{7655}{\micro\second}. This does not correspond at all to the calculated mean response time. This can again be explained by the fact that our model is not appropriate for handling parallelism. High service rate means, for M/M/1 model, that the requests are processed quickly and do not spend much time in service and, in consequence, in the middleware. In reality it takes some time to process the request, which results in way higher measured time spent in the middleware. The same applies for mean waiting time (time in the queue) and mean service time. From theory we have:
$$E[w] = \rho \frac{1/\mu}{1 - \rho} \approx 82.38\% \cdot \frac{1/16701}{17.62\%} \approx \SI{279.95}{\micro\second}$$
$$E[s] = \frac{1}{\mu} \approx \SI{59.88}{\micro\second}$$

The corresponding values measured by the middleware equal: \SI{3203}{\micro\second} for time spent in the queue (which is part of the system representation) and \SI{2841}{\micro\second} for the time spend in the servers. We can see that measured time spent in the servers is approximately 47 times higher then calculated service time. This value is comparable to 39 requests on the fly (mentioned earlier), but it better corresponds to the parallelism of the middleware, since it also reflects the fact that servers do not have to be busy all the time. Let's not forget here that requests also spend some time waiting for the accepting thread to be parsed, so that the difference between waiting time predicted and measured is even higher.

%TODO: more statistics
To sum up, M/M/1 model does not reflect our middleware properly. It does not take into the account the parallelism and predicted values differ significantly. I have not included calculations for more values, like variance or percentiles, cause they also won't correspond to the values measured by the middleware.

% TODO: explain
%$$E[r] = \frac{1/\mu^2}{(1 - \rho)^2} \approx \frac{1/13893^2}{0.97\%^2}$$
%The 90th percentile calculated equals to : $2.3 E[r] \approx \SI{17138}{\micro\second}$. When we look at the data from middleware we can see that 90th percentile actually equals around \SI{13880}{\micro\second}, which is lower than the time calculated from the model.
% TODO: explain

%We can also calculate the time spent in the queue:
%$$E[w] = \rho \frac{1/\mu}{1 - \rho} \approx 99.03\% \cdot \frac{1/13893}{0.97\%} \approx \SI{7379}{\micro\second}$$
%Mean time spent in the queue (being part of the implementation) measured by the middleware is around \SI{4768}{\micro\second}. The differences here are much more significant then overall response time. This is because the queue from the implementation does not correspond to the queue in the M/M/1 model. Requests have to wait also in the queue for each server and also spend some time in the network (which can be treated as a part of the queue, as explained above). What is more, since we have 3 servers, more requests than 1 can be processed by them in parallel, which means that the time spent in the queue measured will be even lower than this calculated.

%When we look at the data collected from the middleware we can see that the mean time spent in the queue (being part of the implementations) is equal to around \SI{3203}{\micro\second}. The difference between this values stems from the fact that in our model we have one queue, which includes also waiting by the request to be handled by the thread handling network messages. As described in the report for milestone 2., this point of the system becomes at some point the bottleneck, so it's reasonable that waiting time here is also significant.

\clearpage

\section{Analysis of System Based on Scalability Data}\label{sec:analysis-scalability}

\iffalse
Length: 1-4 pages

Starting from the different configurations that you used in the second milestone, build M/M/m queuing models of the system as a whole. Detail the characteristics of these series of models and compare them with experimental data. The goal is the analysis of the model and the real scalability of the system (explain the similarities, the differences, and map them to aspects of the design or the experiments). Make sure to follow the model-related guidelines described in the Notes!
\fi

\clearpage

\section{System as Network of Queues}\label{sec:network-of-queues}

Length: 1-3 pages

Based on the outcome of the different modeling efforts from the previous sections, build a comprehensive network of queues model for the whole system. Compare it with experimental data and use the methods discussed in the lecture and the book to provide an in-depth analysis of the behavior. This includes the identification and analysis of bottlenecks in your system. Make sure to follow the model-related guidelines described in the Notes!

\clearpage

\section{Factorial Experiment}\label{sec:2k-experiment}

\iffalse
Length: 1-3 pages

Design a $2^k$ factorial experiment and follow the best practices outlined in the book and in the lecture to analyze the results. You are free to choose the parameters for the experiment and in case you have already collected data in the second milestone that can be used as source for this experiment, you can reuse it. Otherwise, in case you need to run new experiments anyway, we recommend exploring the impact of request size on the middleware together with an other parameter.
\fi

In the milestone 2 we have analyzed thoroughly the impact of the replication factor and impact of the writes percentage on performance of the system. We have not, however, concentrated our attention on which of these factors plays the biggest role when it comes to the performance of the system. Therefore, for this factorial experiment I have decided to investigate the impact of two factors: replication factor and percentage of writes requests. This enabled me to reuse data from the milestone 2, task "Effect of Writes" (using logs {\it writes\_general} from the previous report). We will look at the behavior of 5 servers (since for this number of servers we have chosen optimal number of threads - see report for milestone 2, task "Maximum Throughput").

We will present here $2^kr$ factorial design experiment with repetitions, where $k = 2$ (2 parameters) and $r = 3$ (3 repetitions for each configuration).

Let $A$ be the percentage of writes parameter and $B$ be the replication factor parameter. We will look at the extreme values for these two parameters - 1\% and 10\% as writes percentage; none and all as replication factor. Let us now define two variable $x_A$ and $x_B$ as follows:
\begin{gather*}
x_A = 
\begin{cases}
-1 \qquad \text{ if writes percentage equals 1\%} \\ 
\;\;\;1 \qquad \text{ if writes percentage equals 10\%} \\ 
\end{cases}
\end{gather*}

\begin{gather*}
x_B = 
\begin{cases}
-1 \qquad \text{ if replication factor is none} \\ 
\;\;\;1 \qquad \text{ if replication factor is all} \\ 
\end{cases}
\end{gather*}

As the metric for measuring performance we choose aggregated throughput. Selecting additional metric - response time - would be redundant since in close system according to interactive response time law values to these 2 parameters are strictly corresponding.

We can now regress on $x_A$ and $x_B$ the performance of the system using a nonlinear regression model of the form:
$$y = q_0 + q_Ax_A + q_Bx_B + q_{AB}x_Ax_B$$
In order to calculate the coefficients, we will use sign table presented in the book.
\medskip

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline $I$ & $A$ & $B$ & $AB$ & $y$ &Mean $\bar{y}$ \\
\hline	1	&	-1	&	-1	&	1	&	(	12833	,	12684	,	12974	) &	12830	\\
\hline	1	&	1	&	-1	&	-1	&	(	12732	,	12038	,	12121	) &	12297	\\
\hline	1	&	-1	&	1	&	-1	&	(	12140	,	12667	,	12533	) &	12447	\\
\hline	1	&	1	&	1	&	1	&	(	10582	,	11077	,	10188	) &	10616	\\
\hline	48190	&	-2364	&	-2065	&	-1298	&							&	Total	\\
\hline	12047	&	-591	&	-516	&	-324	&							&	Total / 4	\\
\hline
\end{tabular}
\end{center}
\medskip

From the table above we now see calculated effects ($q$ coefficients): $q_0 \approx 12047$, $q_A \approx -591$, $q_B \approx -516$, $q_{AB} \approx -324$.

We can now use the model to estimate the experimental errors. Using the effects calculated above we have:
$$\hat{y_i} =  q_0 + q_Ax_{Ai} + q_Bx_{Bi} + q_{AB}x_{Ai}x_{Bi},$$
where $\hat{y_i}$ is the estimated performance when factors $A$ and $B$ are at levels $x_{Ai}$ and $x_{Bi}$ respectively.

The error for $j$th replication of $i$th experiment is given by the formula:
$$e_{ij} = y_{ij} - \hat{y_i} = y_{ij} -  (q_0 + q_Ax_{Ai} + q_Bx_{Bi} + q_{AB}x_{Ai}x_{Bi})$$

We can calculate the error looking at the data collected from the experiment. It is worth noticing here, that $\hat{y_i}$ is equal to the mean of values from $i$th experiment. The results are presented in the following table:
\medskip

\begin{center}
\begin{tabular}{@{}|c|cccc|c|ccc|ccc|}
\hline & \multicolumn{4}{c|}{Effect} & \parbox[t]{2.1cm}{Estimated performance} & \multicolumn{3}{c|}{Measured performance} & \multicolumn{3}{c|}{Errors} \\
\hline & $I$ & $A$ & $B$ & $AB$ & & & & & & & \\
\hline i & 12047	&	-591	&	-516	&	-324 & $\hat{y_i} $ & $y_{i1}$ & $y_{i2}$ & $y_{i3}$	& $e_{i1}$ & $e_{i2}$ & $e_{i3}$ \\
\hline	1	&	1	&	-1	&	-1	&	1	&	12830	&	12833	&	12684	&	12974	&	3	&	-146	&	144	\\
\hline	2	&	1	&	1	&	-1	&	-1	&	12297	&	12732	&	12038	&	12121	&	435	&	-259	&	-176	\\
\hline	3	&	1	&	-1	&	1	&	-1	&	12447	&	12140	&	12667	&	12533	&	-307	&	220	&	86	\\
\hline	4	&	1	&	1	&	1	&	1	&	10616	&	10582	&	11077	&	10188	&	-34	&	461	&	-428	\\
\hline
\end{tabular}
\end{center}
\medskip

We can now calculate the sum of the squared errors - $SSE$ - which we will use later to estimate the variance of the errors:
$$SSE = \sum_{i = 1}^{2^2} \sum_{j = 1}^3 e_{ij}^2 = 876248$$

Now we want to calculate the allocation of variation. The total variation or Total Sum of Squares is equal to:
$$SST = \sum_{i, j} (y_{ij} - \bar{y})^2$$
and can be divided into four parts (which is proved in the book):
$$ \sum_{i, j} (y_{ij} - \bar{y})^2 = 2^2\cdot 3 \cdot q_A^2 + 2^2\cdot 3 \cdot q_B^2 + 2^2\cdot 3 \cdot q_{AB}^2 + \sum_{i, j} e_{ij}^2$$
$$SST = SSA + SSB + SSAB + SSE,$$
where $SS*$ corresponds to the appropriate part from the formula above. Let us now calculate these values based on experimental results (values rounded to the nearest integer):
$$SS0 = 2^2\cdot 3 \cdot q_0^2 = 1741682980 $$
$$SSA = 2^2\cdot 3 \cdot q_A^2 = 4192554$$
$$SSB = 2^2\cdot 3 \cdot q_B^2 = 3198169$$
$$SSAB = 2^2\cdot 3 \cdot q_{AB}^2 = 1262954$$

Now we can calculate $SST$:
$$SST = SSA + SSB + SSAB + SSE = 9529925$$
That enables us to divide the total variation into to parts. When we mark variation as $V$ variable with appropriate prefix, we have:
$$VA =  4192554/ 9529925 \approx 43.99\%$$
$$VB =  3198169 / 9529925 \approx 33.56\%$$
$$VAB =  1262954 / 9529925 \approx 13.25\%$$
$$VE =  876248 / 9529925 \approx 9.19\%$$
We can therefore conclude that facotr $A$ - percentage of writes - explains around 44\% of variation and is the most significant factor. Factor $B$ - replication factor - explains  around $34\%$ of the variation, interaction $AB$ - around 13\%. The remaining around 9\% is unexplained and is attributed to errors.
%TODO analyze in context of the system

Both of the parameters analyzed in this experiment cause the decrease in the performance as we increase them. Both these parameters increase the number of set requests that have to be sent to the memcached servers. However, increasing the writes percentage also decreases the reads percentage. Above analysis has shown that most impact can be attributed to increasing the writes percentage rather than increasing the replication factor, although the difference is not that big.

These results can be explained by a couple of factors. Firstly, by increasing the number of writes from 1\% to 10\% we increase the number of set requests by 10 times. Increasing replication factor from none to all for 5 servers means increasing the number of set requests sent to memcached servers 5 times. For $A$ factor we then increase the number of requests twice as much as for the $B$ factor, which can lead to more significant decrease in performance.

Secondly, in the ideal system increasing replication factor should have no or very little impact on the performance of the middleware (as explained in the report for milestone 2). On the other hand, increasing the number of setter requests can, also theoretically, have a significant impact on the performance of the system. This is because for each server we have only one thread processing set requests. When we increase the number of threads by 10 times, this thread will have to serve 10 times more requests and more requests will simply have to wait in the queue, which will decrease the performance of the system. Although in a real world system replication facto has an effect on the system performance, it should be less significant than increasing the writes percentage. 

Let us also analyze impact of the interaction between factors. It is not as significant as one could expect. In the milestone 2 we have shown that the decrease in the performance as we increase the writes percentage becomes significant with replication factor all, whereas for replication factor none it is not so significant. But also similarly we can see that it is only for 10\% writes that we can notice significant decrease in performance as we go from no replication to replication to all. Conducted calculations enable us to say then that it's mostly the influence of each factor separately that causes the significant decrease for the worst-case scenario (10\% writes with replication to all servers). This might be explained by the fact that these factors cause decrease in performance differently. Increasing replication makes us more prone to network latencies and therefore server time for requests is higher which leads to higher response time. On the other hand, increasing writes percentage causes setter worker to have more work to do and increases the ration of slower-processed requests. These ways of decreasing the performance are not that dependent on each other, which is confirmed by the factorial analysis conducted above.

\pagebreak

\section{Interactive Law Verification}\label{sec:interactive-law}

\iffalse
Length: 1-2 pages

Check the validity of all experiments from one of the three sections in your Milestone 2 report using the interactive law (choose a section in which your system has at least 9 different configurations). Analyze the results and explain them in detail.
\fi

I will check the validity of my experiments from section 2. of the Milestone 2 report, where I was analyzing the behavior as we change replication and the number of servers. The number of clients for all configurations was equal to 210. We assume that time clients wait before submitting next request equals approximately to 0 - it is reasonable assumption since every client corresponds to one thread and processing responses and issuing requests 

Below table presents the results of the experiments for different configurations as well as calculated response time. It has been calculated from the formula: $R = \frac{N}{X} - Z$, where $R$ - response time, $N = 210$ - number of clients, $X$ - throughput and $Z=\SI{0}{\micro\second}$ - waiting time for clients before submitting next request. I have also calculated derivation from the theory, which is equal to $\frac{R_e - R}{R}$, where $R_e$ is measured response time.
\medskip

\begin{tabular}{|c|c|c|c|c|c|}
\hline \parbox[t]{2.2cm}{\bf{Replication\\factor}} & \parbox[t]{1.8cm}{\bf{Number of \\servers}} & \parbox[t]{1.5cm}{\bf{TPS \\ \lbrack ops/s \rbrack}} & \parbox[t]{2cm}{\bf{Resp. time [us]\\(measured)}} & \parbox[t]{2.2cm}{\bf{Resp. time [us] \\(interactive law)}} & \parbox[t]{2.4cm}{\bf{Deviation \\ from theory}} \\[3ex]
\hline	none	&	3	&	11884	&	17684	&	17670	&	0.08\%	\\
\hline	half	&	3	&	11969	&	17590	&	17545	&	0.26\%	\\
\hline	all	&	3	&	11641	&	18108	&	18039	&	0.38\%	\\
\hline	none	&	5	&	12169	&	17273	&	17257	&	0.09\%	\\
\hline	half	&	5	&	12046	&	17496	&	17433	&	0.36\%	\\
\hline	all	&	5	&	11231	&	18773	&	18698	&	0.40\%	\\
\hline	none	&	7	&	11817	&	17845	&	17771	&	0.42\%	\\
\hline	half	&	7	&	11048	&	19057	&	19008	&	0.26\%	\\
\hline	all	&	7	&	10145	&	20732	&	20701	&	0.15\%	\\
\hline
\end{tabular}
\medskip

As we can see from above table, the interactive response time law corresponds well to the results from the measurements. Looking at the deviation we can see that response time measured has always been higher than response time calculated using the interactive law. This can be explained by a couple of factors. Firstly, during our experiments we are dealing with tail distribution, which means that spikes in the plots are usually connected with higher response times. This is because we are dealing with the distributed environment in the cloud, where network instability can cause these higher request times. Secondly, we do not know exactly how logging mechanism works in memaslap. It can be the case that the client after receiving response immediately sends a new request and after that it logs receiving of the response. What is more, data from the client can have some small error margin, especially because we are taking into account data only from the part of the running time (after stability reached and before cool down). This might be the cause of these differences. However, these discrepancies are rather small and do not undermine the validity of my experiments.

\pagebreak

\section*{Appendix - changes in the source code}

In order to measure the number of requests being actively processed in the middleware I had to enrich my source code in 2 counters - one keeping track of number of active getter workers, the other one keeping track of set requests for which response we are waiting from the servers. With these 2 counters is connected a necessary synchronization (all getter threads have access to the first counter, all setter threads have access to the second counter), which may decrease the performance of the middleware slightly.
% TODO: add that it doesn't influence it significantly 

\end{document}
